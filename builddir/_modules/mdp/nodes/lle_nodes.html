

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mdp.nodes.lle_nodes &mdash; Modular toolkit for Data Processing (MDP)</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="search" title="Search" href="../../../search.html"/>
    <link rel="top" title="Modular toolkit for Data Processing (MDP)" href="../../../index.html"/>
        <link rel="up" title="mdp.nodes" href="../nodes.html"/> 
<meta name="viewport" content="width=740" />


  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html">
          

          
            
            <img src="../../../_static/logo_animation.gif" class="logo" />
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../documentation.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../how_to_cite_mdp.html">How to cite MDP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contact.html">Contact</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MDP</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../../mdp.html">mdp</a> &raquo;</li>
        
          <li><a href="../nodes.html">mdp.nodes</a> &raquo;</li>
        
      <li>mdp.nodes.lle_nodes</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for mdp.nodes.lle_nodes</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">builtins</span> <span class="k">import</span> <span class="nb">range</span>
<span class="kn">from</span> <span class="nn">past.utils</span> <span class="k">import</span> <span class="n">old_div</span>
<span class="n">__docformat__</span> <span class="o">=</span> <span class="s2">&quot;restructuredtext en&quot;</span>

<span class="kn">from</span> <span class="nn">mdp</span> <span class="k">import</span> <span class="n">numx</span><span class="p">,</span> <span class="n">numx_linalg</span><span class="p">,</span> <span class="n">Cumulator</span><span class="p">,</span> <span class="n">TrainingException</span><span class="p">,</span> <span class="n">MDPWarning</span>
<span class="kn">from</span> <span class="nn">mdp.utils</span> <span class="k">import</span> <span class="n">mult</span><span class="p">,</span> <span class="n">nongeneral_svd</span><span class="p">,</span> <span class="n">svd</span><span class="p">,</span> <span class="n">sqrtm</span><span class="p">,</span> <span class="n">symeig</span>
<span class="kn">import</span> <span class="nn">warnings</span> <span class="k">as</span> <span class="nn">_warnings</span>

<span class="c1"># some useful functions</span>
<span class="n">sqrt</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">sqrt</span>

<span class="c1"># search XXX for locations where future work is needed</span>

<span class="c1">#########################################################</span>
<span class="c1">#  Locally Linear Embedding</span>
<span class="c1">#########################################################</span>

<span class="k">class</span> <span class="nc">LLENode</span><span class="p">(</span><span class="n">Cumulator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perform a Locally Linear Embedding analysis on the data.</span>

<span class="sd">    **Internal variables of interest**</span>

<span class="sd">      ``self.training_projection``</span>
<span class="sd">          The LLE projection of the training data (defined when</span>
<span class="sd">          training finishes).</span>

<span class="sd">      ``self.desired_variance``</span>
<span class="sd">          variance limit used to compute intrinsic dimensionality.</span>

<span class="sd">    Based on the algorithm outlined in *An Introduction to Locally</span>
<span class="sd">    Linear Embedding* by L. Saul and S. Roweis, using improvements</span>
<span class="sd">    suggested in *Locally Linear Embedding for Classification* by</span>
<span class="sd">    D. deRidder and R.P.W. Duin.</span>

<span class="sd">    References: Roweis, S. and Saul, L., Nonlinear dimensionality</span>
<span class="sd">    reduction by locally linear embedding, Science 290 (5500), pp.</span>
<span class="sd">    2323-2326, 2000.</span>

<span class="sd">    Original code contributed by: Jake VanderPlas, University of Washington,</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">svd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">input_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :Arguments:</span>
<span class="sd">           k</span>
<span class="sd">             number of nearest neighbors to use</span>
<span class="sd">           r</span>
<span class="sd">             regularization constant; if ``None``, ``r`` is automatically</span>
<span class="sd">             computed using the method presented in deRidder and Duin;</span>
<span class="sd">             this method involves solving an eigenvalue problem for</span>
<span class="sd">             every data point, and can slow down the algorithm</span>
<span class="sd">             If specified, it multiplies the trace of the local covariance</span>
<span class="sd">             matrix of the distances, as in Saul &amp; Roweis (faster)</span>
<span class="sd">           svd</span>
<span class="sd">             if true, use SVD to compute the projection matrix;</span>
<span class="sd">             SVD is slower but more stable</span>
<span class="sd">           verbose</span>
<span class="sd">             if true, displays information about the progress</span>
<span class="sd">             of the algorithm</span>
<span class="sd">           output_dim</span>
<span class="sd">             number of dimensions to output or a float between 0.0 and</span>
<span class="sd">             1.0. In the latter case, ``output_dim`` specifies the desired</span>
<span class="sd">             fraction of variance to be explained, and the final</span>
<span class="sd">             number of output dimensions is known at the end of</span>
<span class="sd">             training (e.g., for ``output_dim=0.95`` the algorithm will</span>
<span class="sd">             keep as many dimensions as necessary in order to explain</span>
<span class="sd">             95% of the input variance)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="n">output_dim</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">desired_variance</span> <span class="o">=</span> <span class="n">output_dim</span>
            <span class="n">output_dim</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">desired_variance</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">LLENode</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">r</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">svd</span> <span class="o">=</span> <span class="n">svd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

<div class="viewcode-block" id="LLENode._stop_training"><a class="viewcode-back" href="../../../node_list.html#mdp.nodes.LLENode._stop_training">[docs]</a>    <span class="k">def</span> <span class="nf">_stop_training</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">Cumulator</span><span class="o">.</span><span class="n">_stop_training</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;training LLE on </span><span class="si">%i</span><span class="s1"> points&#39;</span>
                   <span class="s1">&#39; in </span><span class="si">%i</span><span class="s1"> dimensions...&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="c1"># some useful quantities</span>
        <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span>

        <span class="c1"># indices of diagonal elements</span>
        <span class="n">W_diag_idx</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="n">Q_diag_idx</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="n">N</span><span class="p">:</span>
            <span class="n">err</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;k=</span><span class="si">%i</span><span class="s1"> must be less than or &#39;</span>
                   <span class="s1">&#39;equal to number of training points N=</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
            <span class="k">raise</span> <span class="n">TrainingException</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

        <span class="c1"># determines number of output dimensions: if desired_variance</span>
        <span class="c1"># is specified, we need to learn it from the data. Otherwise,</span>
        <span class="c1"># it&#39;s easy</span>
        <span class="n">learn_outdim</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">desired_variance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">learn_outdim</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># do we need to automatically determine the regularization term?</span>
        <span class="n">auto_reg</span> <span class="o">=</span> <span class="n">r</span> <span class="ow">is</span> <span class="kc">None</span>

        <span class="c1"># determine number of output dims, precalculate useful stuff</span>
        <span class="k">if</span> <span class="n">learn_outdim</span><span class="p">:</span>
            <span class="n">Qs</span><span class="p">,</span> <span class="n">sig2s</span><span class="p">,</span> <span class="n">nbrss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_adjust_output_dim</span><span class="p">()</span>

        <span class="c1"># build the weight matrix</span>
        <span class="c1">#XXX future work:</span>
        <span class="c1">#XXX   for faster implementation, W should be a sparse matrix</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; - constructing [</span><span class="si">%i</span><span class="s1"> x </span><span class="si">%i</span><span class="s1">] weight matrix...&#39;</span> <span class="o">%</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">learn_outdim</span><span class="p">:</span>
                <span class="n">Q</span> <span class="o">=</span> <span class="n">Qs</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
                <span class="n">nbrs</span> <span class="o">=</span> <span class="n">nbrss</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># -----------------------------------------------</span>
                <span class="c1">#  find k nearest neighbors</span>
                <span class="c1"># -----------------------------------------------</span>
                <span class="n">M_Mi</span> <span class="o">=</span> <span class="n">M</span><span class="o">-</span><span class="n">M</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
                <span class="n">nbrs</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">argsort</span><span class="p">((</span><span class="n">M_Mi</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">))[</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">M_Mi</span> <span class="o">=</span> <span class="n">M_Mi</span><span class="p">[</span><span class="n">nbrs</span><span class="p">]</span>
                <span class="c1"># compute covariance matrix of distances</span>
                <span class="n">Q</span> <span class="o">=</span> <span class="n">mult</span><span class="p">(</span><span class="n">M_Mi</span><span class="p">,</span> <span class="n">M_Mi</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

            <span class="c1"># -----------------------------------------------</span>
            <span class="c1">#  compute weight vector based on neighbors</span>
            <span class="c1"># -----------------------------------------------</span>

            <span class="c1">#Covariance matrix may be nearly singular:</span>
            <span class="c1"># add a diagonal correction to prevent numerical errors</span>
            <span class="k">if</span> <span class="n">auto_reg</span><span class="p">:</span>
                <span class="c1"># automatic mode: correction is equal to the sum of</span>
                <span class="c1"># the (d_in-d_out) unused variances (as in deRidder &amp;</span>
                <span class="c1"># Duin)</span>
                <span class="k">if</span> <span class="n">learn_outdim</span><span class="p">:</span>
                    <span class="n">sig2</span> <span class="o">=</span> <span class="n">sig2s</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="p">:]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">sig2</span> <span class="o">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">M_Mi</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
                <span class="n">r</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sig2</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">:])</span>
                <span class="n">Q</span><span class="p">[</span><span class="n">Q_diag_idx</span><span class="p">,</span> <span class="n">Q_diag_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">r</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Roweis et al instead use &quot;a correction that</span>
                <span class="c1">#   is small compared to the trace&quot; e.g.:</span>
                <span class="c1"># r = 0.001 * float(Q.trace())</span>
                <span class="c1"># this is equivalent to assuming 0.1% of the variance is unused</span>
                <span class="n">Q</span><span class="p">[</span><span class="n">Q_diag_idx</span><span class="p">,</span> <span class="n">Q_diag_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">r</span><span class="o">*</span><span class="n">Q</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span>

            <span class="c1">#solve for weight</span>
            <span class="c1"># weight is w such that sum(Q_ij * w_j) = 1 for all i</span>
            <span class="c1"># XXX refcast is due to numpy bug: floats become double</span>
            <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_refcast</span><span class="p">(</span><span class="n">numx_linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">numx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">k</span><span class="p">)))</span>
            <span class="n">w</span> <span class="o">/=</span> <span class="n">w</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="c1">#update row of the weight matrix</span>
            <span class="n">W</span><span class="p">[</span><span class="n">nbrs</span><span class="p">,</span> <span class="n">row</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39; - finding [</span><span class="si">%i</span><span class="s1"> x </span><span class="si">%i</span><span class="s1">] null space of weight matrix</span><span class="se">\n</span><span class="s1">&#39;</span>
                   <span class="s1">&#39;     (may take a while)...&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1">#to find the null space, we need the bottom d+1</span>
        <span class="c1">#  eigenvectors of (W-I).T*(W-I)</span>
        <span class="c1">#Compute this using the svd of (W-I):</span>
        <span class="n">W</span><span class="p">[</span><span class="n">W_diag_idx</span><span class="p">,</span> <span class="n">W_diag_idx</span><span class="p">]</span> <span class="o">-=</span> <span class="mf">1.</span>

        <span class="c1">#XXX future work:</span>
        <span class="c1">#XXX  use of upcoming ARPACK interface for bottom few eigenvectors</span>
        <span class="c1">#XXX   of a sparse matrix will significantly increase the speed</span>
        <span class="c1">#XXX   of the next step</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">svd</span><span class="p">:</span>
            <span class="n">sig</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">nongeneral_svd</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># the following code does the same computation, but uses</span>
            <span class="c1"># symeig, which computes only the required eigenvectors, and</span>
            <span class="c1"># is much faster. However, it could also be more unstable...</span>
            <span class="n">WW</span> <span class="o">=</span> <span class="n">mult</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="c1"># regularizes the eigenvalues, does not change the eigenvectors:</span>
            <span class="n">WW</span><span class="p">[</span><span class="n">W_diag_idx</span><span class="p">,</span> <span class="n">W_diag_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">0.1</span>
            <span class="n">sig</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">symeig</span><span class="p">(</span><span class="n">WW</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training_projection</span> <span class="o">=</span> <span class="n">U</span></div>

<div class="viewcode-block" id="LLENode._adjust_output_dim"><a class="viewcode-back" href="../../../node_list.html#mdp.nodes.LLENode._adjust_output_dim">[docs]</a>    <span class="k">def</span> <span class="nf">_adjust_output_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># this function is called if we need to compute the number of</span>
        <span class="c1"># output dimensions automatically; some quantities that are</span>
        <span class="c1"># useful later are pre-calculated to spare precious time</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; - adjusting output dim:&#39;</span><span class="p">)</span>

        <span class="c1">#otherwise, we need to compute output_dim</span>
        <span class="c1">#                  from desired_variance</span>
        <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">d_in</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">m_est_array</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">Qs</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>
        <span class="n">sig2s</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">d_in</span><span class="p">))</span>
        <span class="n">nbrss</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;i&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="c1">#-----------------------------------------------</span>
            <span class="c1">#  find k nearest neighbors</span>
            <span class="c1">#-----------------------------------------------</span>
            <span class="n">M_Mi</span> <span class="o">=</span> <span class="n">M</span><span class="o">-</span><span class="n">M</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
            <span class="n">nbrs</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">argsort</span><span class="p">((</span><span class="n">M_Mi</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">))[</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">M_Mi</span> <span class="o">=</span> <span class="n">M_Mi</span><span class="p">[</span><span class="n">nbrs</span><span class="p">]</span>
            <span class="c1"># compute covariance matrix of distances</span>
            <span class="n">Qs</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">mult</span><span class="p">(</span><span class="n">M_Mi</span><span class="p">,</span> <span class="n">M_Mi</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">nbrss</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">nbrs</span>

            <span class="c1">#-----------------------------------------------</span>
            <span class="c1"># singular values of M_Mi give the variance:</span>
            <span class="c1">#   use this to compute intrinsic dimensionality</span>
            <span class="c1">#   at this point</span>
            <span class="c1">#-----------------------------------------------</span>
            <span class="n">sig2</span> <span class="o">=</span> <span class="p">(</span><span class="n">svd</span><span class="p">(</span><span class="n">M_Mi</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">sig2s</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="p">:</span><span class="n">sig2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">sig2</span>

            <span class="c1">#-----------------------------------------------</span>
            <span class="c1"># use sig2 to compute intrinsic dimensionality of the</span>
            <span class="c1">#   data at this neighborhood.  The dimensionality is the</span>
            <span class="c1">#   number of eigenvalues needed to sum to the total</span>
            <span class="c1">#   desired variance</span>
            <span class="c1">#-----------------------------------------------</span>
            <span class="n">sig2</span> <span class="o">/=</span> <span class="n">sig2</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">S</span> <span class="o">=</span> <span class="n">sig2</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span>
            <span class="n">m_est</span> <span class="o">=</span> <span class="n">S</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">desired_variance</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">m_est</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">m_est</span> <span class="o">+=</span> <span class="n">old_div</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">desired_variance</span><span class="o">-</span><span class="n">S</span><span class="p">[</span><span class="n">m_est</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span><span class="n">sig2</span><span class="p">[</span><span class="n">m_est</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">m_est</span> <span class="o">=</span> <span class="n">old_div</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">desired_variance</span><span class="p">,</span><span class="n">sig2</span><span class="p">[</span><span class="n">m_est</span><span class="p">])</span>
            <span class="n">m_est_array</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m_est</span><span class="p">)</span>

        <span class="n">m_est_array</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">m_est_array</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="n">numx</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span> <span class="n">numx</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">m_est_array</span><span class="p">)</span> <span class="p">)</span> <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;      output_dim = </span><span class="si">%i</span><span class="s1">&#39;</span>
                   <span class="s1">&#39; for variance of </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">desired_variance</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Qs</span><span class="p">,</span> <span class="n">sig2s</span><span class="p">,</span> <span class="n">nbrss</span></div>

<div class="viewcode-block" id="LLENode._execute"><a class="viewcode-back" href="../../../node_list.html#mdp.nodes.LLENode._execute">[docs]</a>    <span class="k">def</span> <span class="nf">_execute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1">#----------------------------------------------------</span>
        <span class="c1"># similar algorithm to that within self.stop_training()</span>
        <span class="c1">#  refer there for notes &amp; comments on code</span>
        <span class="c1">#----------------------------------------------------</span>
        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">Nx</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Nx</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">k</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span>
        <span class="n">d_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span>
        <span class="n">Q_diag_idx</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nx</span><span class="p">):</span>
            <span class="c1">#find nearest neighbors of x in M</span>
            <span class="n">M_xi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
            <span class="n">nbrs</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span> <span class="p">(</span><span class="n">M_xi</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">)[:</span><span class="n">k</span><span class="p">]</span>
            <span class="n">M_xi</span> <span class="o">=</span> <span class="n">M_xi</span><span class="p">[</span><span class="n">nbrs</span><span class="p">]</span>

            <span class="c1">#find corrected covariance matrix Q</span>
            <span class="n">Q</span> <span class="o">=</span> <span class="n">mult</span><span class="p">(</span><span class="n">M_xi</span><span class="p">,</span> <span class="n">M_xi</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="n">d_out</span><span class="p">:</span>
                <span class="n">sig2</span> <span class="o">=</span> <span class="p">(</span><span class="n">svd</span><span class="p">(</span><span class="n">M_xi</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>
                <span class="n">r</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sig2</span><span class="p">[</span><span class="n">d_out</span><span class="p">:])</span>
                <span class="n">Q</span><span class="p">[</span><span class="n">Q_diag_idx</span><span class="p">,</span> <span class="n">Q_diag_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">r</span>
            <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">Q</span><span class="p">[</span><span class="n">Q_diag_idx</span><span class="p">,</span> <span class="n">Q_diag_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">r</span>

            <span class="c1">#solve for weights</span>
            <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_refcast</span><span class="p">(</span><span class="n">numx_linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Q</span> <span class="p">,</span> <span class="n">numx</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">k</span><span class="p">)))</span>
            <span class="n">w</span> <span class="o">/=</span> <span class="n">w</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">W</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">nbrs</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span>

        <span class="c1">#multiply weights by result of SVD from training</span>
        <span class="k">return</span> <span class="n">numx</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_projection</span><span class="p">)</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">is_trainable</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">is_invertible</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="c1">#########################################################</span>
<span class="c1">#  Hessian LLE</span>
<span class="c1">#########################################################</span>


<span class="c1"># Modified Gram-Schmidt</span>
<div class="viewcode-block" id="_mgs"><a class="viewcode-back" href="../../../mdp/mdp.nodes.lle_nodes.html#mdp.nodes._mgs">[docs]</a><span class="k">def</span> <span class="nf">_mgs</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">r</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">numx_linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
        <span class="n">v</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">old_div</span><span class="p">(</span><span class="n">v</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span><span class="n">r</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="n">r</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">mult</span><span class="p">(</span><span class="n">v</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">v</span><span class="p">[:,</span> <span class="n">j</span><span class="p">])</span>
            <span class="n">v</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">r</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">v</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
    <span class="c1"># q is v</span>
    <span class="k">return</span> <span class="n">v</span><span class="p">,</span> <span class="n">r</span></div>

<span class="k">class</span> <span class="nc">HLLENode</span><span class="p">(</span><span class="n">LLENode</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perform a Hessian Locally Linear Embedding analysis on the data.</span>

<span class="sd">    **Internal variables of interest**</span>

<span class="sd">      ``self.training_projection``</span>
<span class="sd">          the HLLE projection of the training data (defined when training</span>
<span class="sd">          finishes)</span>

<span class="sd">      ``self.desired_variance``</span>
<span class="sd">          variance limit used to compute intrinsic dimensionality.</span>

<span class="sd">    Implementation based on algorithm outlined in</span>
<span class="sd">    Donoho, D. L., and Grimes, C., Hessian Eigenmaps: new locally linear</span>
<span class="sd">    embedding techniques for high-dimensional data, Proceedings of the</span>
<span class="sd">    National Academy of Sciences 100(10): 5591-5596, 2003.</span>

<span class="sd">    Original code contributed by: Jake Vanderplas, University of Washington</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">#----------------------------------------------------</span>
    <span class="c1"># Note that many methods ar inherited from LLENode,</span>
    <span class="c1">#  including _execute(), _adjust_output_dim(), etc.</span>
    <span class="c1"># The main advantage of the Hessian estimator is to</span>
    <span class="c1">#  limit distortions of the input manifold.  Once</span>
    <span class="c1">#  the model has been trained, it is sufficient (and</span>
    <span class="c1">#  much less computationally intensive) to determine</span>
    <span class="c1">#  projections for new points using the LLE framework.</span>
    <span class="c1">#----------------------------------------------------</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">svd</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">input_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :Keyword arguments:</span>
<span class="sd">           k</span>
<span class="sd">              number of nearest neighbors to use; the node will raise</span>
<span class="sd">              an MDPWarning if k is smaller than</span>
<span class="sd">              k &gt;= 1 + output_dim + output_dim*(output_dim+1)/2,</span>
<span class="sd">              because in this case a less efficient computation must be</span>
<span class="sd">              used, and the ablgorithm can become unstable</span>
<span class="sd">           r</span>
<span class="sd">              regularization constant; as opposed to LLENode, it is</span>
<span class="sd">              not possible to compute this constant automatically; it is</span>
<span class="sd">              only used during execution</span>
<span class="sd">           svd</span>
<span class="sd">              if true, use SVD to compute the projection matrix;</span>
<span class="sd">              SVD is slower but more stable</span>
<span class="sd">           verbose</span>
<span class="sd">              if true, displays information about the progress</span>
<span class="sd">              of the algorithm</span>
<span class="sd">           output_dim</span>
<span class="sd">              number of dimensions to output or a float between 0.0</span>
<span class="sd">              and 1.0. In the latter case, output_dim specifies the</span>
<span class="sd">              desired fraction of variance to be exaplained, and the</span>
<span class="sd">              final number of output dimensions is known at the end of</span>
<span class="sd">              training (e.g., for &#39;output_dim=0.95&#39; the algorithm will</span>
<span class="sd">              keep as many dimensions as necessary in order to explain</span>
<span class="sd">              95% of the input variance)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">LLENode</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">svd</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span>
                         <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

<div class="viewcode-block" id="HLLENode._stop_training"><a class="viewcode-back" href="../../../node_list.html#mdp.nodes.HLLENode._stop_training">[docs]</a>    <span class="k">def</span> <span class="nf">_stop_training</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">Cumulator</span><span class="o">.</span><span class="n">_stop_training</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span>
        <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="n">N</span><span class="p">:</span>
            <span class="n">err</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;k=</span><span class="si">%i</span><span class="s1"> must be less than&#39;</span>
                   <span class="s1">&#39; or equal to number of training points N=</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
            <span class="k">raise</span> <span class="n">TrainingException</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;performing HLLE on </span><span class="si">%i</span><span class="s1"> points in </span><span class="si">%i</span><span class="s1"> dimensions...&#39;</span> <span class="o">%</span> <span class="n">M</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># determines number of output dimensions: if desired_variance</span>
        <span class="c1"># is specified, we need to learn it from the data. Otherwise,</span>
        <span class="c1"># it&#39;s easy</span>
        <span class="n">learn_outdim</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">desired_variance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">learn_outdim</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># determine number of output dims, precalculate useful stuff</span>
        <span class="k">if</span> <span class="n">learn_outdim</span><span class="p">:</span>
            <span class="n">Qs</span><span class="p">,</span> <span class="n">sig2s</span><span class="p">,</span> <span class="n">nbrss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_adjust_output_dim</span><span class="p">()</span>

        <span class="n">d_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span>

        <span class="c1">#dp = d_out + (d_out-1) + (d_out-2) + ...</span>
        <span class="n">dp</span> <span class="o">=</span> <span class="n">d_out</span><span class="o">*</span><span class="p">(</span><span class="n">d_out</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span>

        <span class="k">if</span> <span class="nb">min</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">d_out</span><span class="p">:</span>
            <span class="n">err</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;k=</span><span class="si">%i</span><span class="s1"> and n=</span><span class="si">%i</span><span class="s1"> (number of input data points) must be&#39;</span>
                   <span class="s1">&#39; larger than output_dim=</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">d_out</span><span class="p">))</span>
            <span class="k">raise</span> <span class="n">TrainingException</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="o">+</span><span class="n">d_out</span><span class="o">+</span><span class="n">dp</span><span class="p">:</span>
            <span class="n">wrn</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;The number of neighbours, k=</span><span class="si">%i</span><span class="s1">, is smaller than&#39;</span>
                   <span class="s1">&#39; 1 + output_dim + output_dim*(output_dim+1)/2 = </span><span class="si">%i</span><span class="s1">,&#39;</span>
                   <span class="s1">&#39; which might result in unstable results.&#39;</span>
                   <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="o">+</span><span class="n">d_out</span><span class="o">+</span><span class="n">dp</span><span class="p">))</span>
            <span class="n">_warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">wrn</span><span class="p">,</span> <span class="n">MDPWarning</span><span class="p">)</span>

        <span class="c1">#build the weight matrix</span>
        <span class="c1">#XXX   for faster implementation, W should be a sparse matrix</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">dp</span><span class="o">*</span><span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; - constructing [</span><span class="si">%i</span><span class="s1"> x </span><span class="si">%i</span><span class="s1">] weight matrix...&#39;</span> <span class="o">%</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">learn_outdim</span><span class="p">:</span>
                <span class="n">nbrs</span> <span class="o">=</span> <span class="n">nbrss</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># -----------------------------------------------</span>
                <span class="c1">#  find k nearest neighbors</span>
                <span class="c1"># -----------------------------------------------</span>
                <span class="n">M_Mi</span> <span class="o">=</span> <span class="n">M</span><span class="o">-</span><span class="n">M</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
                <span class="n">nbrs</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">argsort</span><span class="p">((</span><span class="n">M_Mi</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">))[</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1">#-----------------------------------------------</span>
            <span class="c1">#  center the neighborhood using the mean</span>
            <span class="c1">#-----------------------------------------------</span>
            <span class="n">nbrhd</span> <span class="o">=</span> <span class="n">M</span><span class="p">[</span><span class="n">nbrs</span><span class="p">]</span> <span class="c1"># this makes a copy</span>
            <span class="n">nbrhd</span> <span class="o">-=</span> <span class="n">nbrhd</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1">#-----------------------------------------------</span>
            <span class="c1">#  compute local coordinates</span>
            <span class="c1">#   using a singular value decomposition</span>
            <span class="c1">#-----------------------------------------------</span>
            <span class="n">U</span><span class="p">,</span> <span class="n">sig</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">nbrhd</span><span class="p">)</span>
            <span class="n">nbrhd</span> <span class="o">=</span> <span class="n">U</span><span class="o">.</span><span class="n">T</span><span class="p">[:</span><span class="n">d_out</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">VT</span>

            <span class="c1">#-----------------------------------------------</span>
            <span class="c1">#  build Hessian estimator</span>
            <span class="c1">#-----------------------------------------------</span>
            <span class="n">Yi</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">dp</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">ct</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d_out</span><span class="p">):</span>
                <span class="n">Yi</span><span class="p">[</span><span class="n">ct</span><span class="p">:</span><span class="n">ct</span><span class="o">+</span><span class="n">d_out</span><span class="o">-</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">nbrhd</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">nbrhd</span><span class="p">[</span><span class="n">i</span><span class="p">:,</span> <span class="p">:]</span>
                <span class="n">ct</span> <span class="o">+=</span> <span class="n">d_out</span><span class="o">-</span><span class="n">i</span>
            <span class="n">Yi</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">numx</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                                   <span class="n">nbrhd</span><span class="p">,</span> <span class="n">Yi</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>

            <span class="c1">#-----------------------------------------------</span>
            <span class="c1">#  orthogonalize linear and quadratic forms</span>
            <span class="c1">#   with QR factorization</span>
            <span class="c1">#  and make the weights sum to 1</span>
            <span class="c1">#-----------------------------------------------</span>
            <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="o">+</span><span class="n">d_out</span><span class="o">+</span><span class="n">dp</span><span class="p">:</span>
                <span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">numx_linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">Yi</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[:,</span> <span class="n">d_out</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">d_out</span><span class="o">+</span><span class="mi">1</span><span class="o">+</span><span class="n">dp</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">_mgs</span><span class="p">(</span><span class="n">Yi</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">q</span><span class="p">[:,</span> <span class="o">-</span><span class="n">dp</span><span class="p">:]</span>

            <span class="n">S</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#sum along columns</span>
            <span class="c1">#if S[i] is too small, set it equal to 1.0</span>
            <span class="c1"># this prevents weights from blowing up</span>
            <span class="n">S</span><span class="p">[</span><span class="n">numx</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">numx</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">S</span><span class="p">)</span><span class="o">&lt;</span><span class="mf">1E-4</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="c1">#print w.shape, S.shape, (w/S).shape</span>
            <span class="c1">#print W[nbrs, row*dp:(row+1)*dp].shape</span>
            <span class="n">W</span><span class="p">[</span><span class="n">nbrs</span><span class="p">,</span> <span class="n">row</span><span class="o">*</span><span class="n">dp</span><span class="p">:(</span><span class="n">row</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">dp</span><span class="p">]</span> <span class="o">=</span> <span class="n">old_div</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>

        <span class="c1">#-----------------------------------------------</span>
        <span class="c1"># To find the null space, we want the</span>
        <span class="c1">#  first d+1 eigenvectors of W.T*W</span>
        <span class="c1"># Compute this using an svd of W</span>
        <span class="c1">#-----------------------------------------------</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39; - finding [</span><span class="si">%i</span><span class="s1"> x </span><span class="si">%i</span><span class="s1">] &#39;</span>
                   <span class="s1">&#39;null space of weight matrix...&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">d_out</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="c1">#XXX future work:</span>
        <span class="c1">#XXX  use of upcoming ARPACK interface for bottom few eigenvectors</span>
        <span class="c1">#XXX   of a sparse matrix will significantly increase the speed</span>
        <span class="c1">#XXX   of the next step</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">svd</span><span class="p">:</span>
            <span class="n">sig</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">nongeneral_svd</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">d_out</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="n">U</span><span class="o">*</span><span class="n">numx</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">WW</span> <span class="o">=</span> <span class="n">mult</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="c1"># regularizes the eigenvalues, does not change the eigenvectors:</span>
            <span class="n">W_diag_idx</span> <span class="o">=</span> <span class="n">numx</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
            <span class="n">WW</span><span class="p">[</span><span class="n">W_diag_idx</span><span class="p">,</span> <span class="n">W_diag_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">0.01</span>
            <span class="n">sig</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">symeig</span><span class="p">(</span><span class="n">WW</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="n">U</span><span class="o">*</span><span class="n">numx</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">WW</span>
        <span class="k">del</span> <span class="n">W</span>

        <span class="c1">#-----------------------------------------------</span>
        <span class="c1"># Normalize Y</span>
        <span class="c1">#</span>
        <span class="c1"># Alternative way to do it:</span>
        <span class="c1">#  we need R = (Y.T*Y)^(-1/2)</span>
        <span class="c1">#   do this with an SVD of Y            del VT</span>

        <span class="c1">#      Y = U*sig*V.T</span>
        <span class="c1">#      Y.T*Y = (V*sig.T*U.T) * (U*sig*V.T)</span>
        <span class="c1">#            = V * (sig*sig.T) * V.T</span>
        <span class="c1">#            = V * sig^2 V.T</span>
        <span class="c1">#   so</span>
        <span class="c1">#      R = V * sig^-1 * V.T</span>
        <span class="c1"># The code is:</span>
        <span class="c1">#    U, sig, VT = svd(Y)</span>
        <span class="c1">#    del U</span>
        <span class="c1">#    S = numx.diag(sig**-1)</span>
        <span class="c1">#    self.training_projection = mult(Y, mult(VT.T, mult(S, VT)))</span>
        <span class="c1">#-----------------------------------------------</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; - normalizing null space...&#39;</span><span class="p">)</span>

        <span class="n">C</span> <span class="o">=</span> <span class="n">sqrtm</span><span class="p">(</span><span class="n">mult</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Y</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_projection</span> <span class="o">=</span> <span class="n">mult</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span></div>
</pre></div>

           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
      Last updated on 2020-02-17 1:33:02 PM Coordinated Universal Time.

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'3.5',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/language_data.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   
<div class="footer">
    <hr />
    <table>
      <tr>
        <td class="footer-left">
           <a href="http://sourceforge.net/projects/mdp-toolkit">
 <img src="http://sflogo.sourceforge.net/sflogo.php?group_id=116959&amp;type=12"
      width="120" height="30" border="0" alt="MDP@SF.NET"/> </a>
        </td>
        <td class="footer-center">
          Last updated on
             2020-02-17 1:33:02 PM Coordinated Universal Time
        </td>
        <td class="footer-right">
         <form class="search" action="../../../search.html" method="get">
          <input type="submit" value="Search" />
          <input type="text" name="q" size="18" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
         </form>
        </td>
    </table>  
    <!-- Piwik -->
    <script type="text/javascript">
	var pkBaseURL = (("https:" == document.location.protocol) ? "https://sourceforge.net/apps/piwik/mdp-toolkit/" : "http://sourceforge.net/apps/piwik/mdp-toolkit/");
	document.write(unescape("%3Cscript src='" + pkBaseURL + "piwik.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
	piwik_action_name = '';
	piwik_idsite = 1;
	piwik_url = pkBaseURL + "piwik.php";
	piwik_log(piwik_action_name, piwik_idsite, piwik_url);
    </script>
    <object><noscript>
	    <p>
		<img src="http://sourceforge.net/apps/piwik/mdp-toolkit/piwik.php?idsite=1"
		     alt="piwik" />
	    </p>
    </noscript></object>
    <!-- End Piwik Tag -->
</div>   


</body>
</html>