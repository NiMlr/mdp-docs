# This script takes the text image generated by gen_text.py and
# learns a GNG network on top of that.
# it creates a series of png files with the learning process


save = True # save animation and logo
transparent = True # make transparent background
dpi = 100 # image quality

# color codes from pylab
bg_color = 'k'
fg_color = 'r'

N = 500 # data points per iteration
NITER = 50 # number of iterations

noise = 0.1 # noise ratio 0.1 = 10%
max_nodes = 500

import mdp, numpy, pylab, pickle, os, shutil
# set random seed
numpy.random.seed(1)

# create animation directory if not present
if not os.path.exists('animation'): os.mkdir('animation')

print 'Load image.'
fl = file('text.raw', 'rb')
x = pickle.load(fl)
fl.close()
# cast x to be float32
x = x.astype(numpy.float32)

# set figure size
# note: the pylab canvas is still too large! how to fit it to the figure
pylab.ion()
fig = pylab.figure()
fig.set_size_inches((3*x.shape[1]/float(x.shape[0])),3)
fig.add_axes([0.01,0.01,0.98,0.98])

#.set_figsize_inches( (w,h) )

def plot_graph(gng, iter):
    lines = []
    for e in gng.graph.edges:
        x0, y0 = e.head.data.pos
        c0 = x[int(y0), int(x0)]<0.5 and bg_color or fg_color 
        x1, y1 = e.tail.data.pos
        c1 = x[int(y1), int(x1)]<0.5 and bg_color or fg_color
        # determine edge color
        cline = c0==c1 and c0 or bg_color
        lines.extend(([x0,x1], [y0,y1], cline+'-',
                      [x0,x0], [y0,y0], c0+'.',
                      [x1,x1], [y1,y1], c1+'.'))

    pylab.clf()
    pylab.ioff()
    # the order of the axis command is important!
    fig.add_axes([0.01,0.01,0.98,0.98])
    pylab.axis('scaled')
    #pylab.plot(data[:,0], data[:,1], "k.")
    pylab.plot(linewidth=2, ms=14, *lines)
    pylab.axis([0,x.shape[1],0,x.shape[0]])
    pylab.axis('off')
    pylab.draw()
    if save:
        #fig = pylab.gcf()
        fig.frameon = not transparent
        pylab.savefig('animation/img'+('%d'%iter).zfill(4)+'.png',dpi=dpi)
        fig.frameon = True
    pylab.ion()
    

def data_generator(niter):
    for i in range(niter):
        print 'Iteration ', i
        # shuffled lists of indices of the foreground and background pixels 
        idx_fg = x.nonzero()
        idx_bg = (1.-x).nonzero()
        idx_fg = zip(idx_fg[1], idx_fg[0])
        idx_bg = zip(idx_bg[1], idx_bg[0])

        numpy.random.shuffle(idx_fg)
        numpy.random.shuffle(idx_bg)
        N_fg = int(N*(1-noise)) 

        # choose N_fg pixels from fg and N-N_fg pixels from bg
        idx = idx_fg[:N_fg] + idx_bg[:N-N_fg]
        numpy.random.shuffle(idx)
        yield numpy.array(idx).astype('d')

print 'Learning neural gas.'
# neural gas node
gng = mdp.nodes.GrowingNeuralGasNode(max_nodes=max_nodes)
for iter, data in enumerate(data_generator(NITER)):
    gng.train(data)
    plot_graph(gng, iter)
gng.stop_training()

if save:
    shutil.copyfile('animation/img'+('%d'%iter).zfill(4)+'.png', 'logo.png')

raw_input('Press ENTER to quit!\n')

# to generate a gif animation use for example:
# convert -dispose Background -delay 10 animation/*png -loop 1  animation.gif

# to reduce the size of the image, generate an indexed png with 4 colors:
# convert logo.png -matte -colors 4 gif:- | convert - logo_idx.png
# the image is reduced from 79K to 12K!
# reconvert to png and add re-add transparency

# to generate a logo usable for the web page (height=100 pixel)
# either reduce the full logo.png and get a 39K logo:
# convert -resize x100 logo.png logo_small.png
# or put the indexed logo into the website and let the browser scale down.

# to put them in the webpage:
# cp logo_small.png ../images/logo.png
# cp animation.gif ../images/logo_animation.gif
